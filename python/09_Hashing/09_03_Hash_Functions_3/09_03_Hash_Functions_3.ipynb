{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"direction:rtl;line-height:300%;\"><font face=\"XB Zar\" size=5>\n",
    "<div style=\"direction:rtl;line-height:300%;\"><font face=\"XB Zar\" size=5>\n",
    "<div align=center>\n",
    "<font face=\"IranNastaliq\" size=30>\n",
    "<p></p>\n",
    "به نام خدا\n",
    "</font>\n",
    "<br>\n",
    "<font color=#FF7500>\n",
    "دانشگاه صنعتی شریف - دانشکده مهندسی کامپیوتر\n",
    "</font>\n",
    "<br>\n",
    "<font color=blue>\n",
    "داده‌ساختارها و الگوریتم‌ها\n",
    "</font>\n",
    "<br>\n",
    "ترم دوم سال تحصیلی ۱۳۹۸-۱۳۹۷\n",
    "</div>\n",
    "<hr/>\n",
    "<font color=red size=6>\n",
    "<p></p>\n",
    "\n",
    "<div align=center>فصل نهم: توابع درهمسازی(قسمت سوم)</div>\n",
    "</font>\n",
    "<div align=center>\n",
    "محمدمهدی جهان‌آرا، حسام نیک‌پی</div>\n",
    "<hr>\n",
    "</font></div>\n",
    "\n",
    "\n",
    "<style type=\"text/css\" scoped>\n",
    "p{\n",
    "border: 1px solid #a2a9b1;background-color: #f8f9fa;display: inline-block;\n",
    "};\n",
    "</style>\n",
    "\n",
    "<div>\n",
    "<h3> فهرست محتویات</h3>\n",
    "<ul style=\"margin-right: 0;\">\n",
    "<li><a href=\"#section1\">مقدمه</a></li>\n",
    "<li><a href=\"#section2\">مثال: شبکه‌ی اجتماعی کتابخوان‌ها</a></li>\n",
    "<li><a href=\"#section3\">درهمسازی میانی</a></li>\n",
    "<li><a href=\"#section4\">شبیه‌ترین کاربر (نزدیک‌ترین همسایه)</a></li>\n",
    "<li><a href=\"#section5\">درهمسازی حساس به شباهت</a></li>\n",
    "<li><a href=\"#section6\">شبیه‌ترین کتاب!</a></li>\n",
    "</ul>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"direction:rtl;line-height:300%;\"><font face=\"XB Zar\" size=5>\n",
    "<h1><font  id=\"section1\" color=#FF7500 size=6>\n",
    "مقدمه</font></h1>\n",
    "روش‌های درهمسازی برای کاهش ابعاد داده به منظور مقایسه‌ی راحت‌تر و سریع‌تر آن به وجود آمده‌اند. در دو بخش قبلی توابع درهمسازی را بررسی کردیم که به احتمال بالایی برای هر دو داده‌ی متفاوت \n",
    "hash\n",
    "متفاوتی تولید می‌کردند و به عبارتی سعی می‌کردیم تصادم (Collision)\n",
    "را تا بیشترین میزان کم کنیم. این توابع در کاربردهایی مثل تشخیص فایل‌های دقیقا یکسان یا صفحه‌های وب دقیقا یکسان یا ذخیره‌سازی امن رمزها کارآمد هستند.\n",
    "<br>\n",
    "در این بخش توابع درهمسازی را بررسی می‌کنیم که برای داده‌های نزدیک (نسبت به یک تعریف مشخص از فاصله یا شباهت)، به احتمالا بالایی \n",
    "hash\n",
    "یکسان تولید می‌کنند. این توابع در کاربردهایی مثل پیدا کردن صفحه‌های وب با محتوای نزدیک به هم یا پیدا کردن صاحب اثر انگشت یا پیشنهاد دادن دوست به کاربران در شبکه‌های اجتماعی کارآمد هستند!\n",
    "<br>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"direction:rtl;line-height:300%;\"><font face=\"XB Zar\" size=5>\n",
    "<h1><font color=#FF7500 id=\"section2\" size=6>\n",
    "مثال: شبکه‌ی اجتماعی کتابخوان‌ها</font></h1><p></p>\n",
    "فرض کنید یک شبکه‌ی اجتماعی برای افراد کتابخوان طراحی کرده‌اید. هر کسی در این شبکه می‌تواند کتاب‌هایی که مطالعه کرده است را مشخص کند و با افرادی که کتاب‌های مشابهی مطالعه کرده‌اند آشنا شود.\n",
    "<br>\n",
    "برای سادگی فرض کنید می‌خواهیم بخشی به سیستم اضافه کنیم که شبیه‌ترین کاربر را به ازای هر کاربر داده شده پیدا می‌کند.\n",
    "<h2><font color=#FF7500 size=5> معیار شباهت </font></h2>\n",
    "اطلاعات مربوط به هر کاربر را می‌توان با یک بردار \n",
    "$m$\n",
    "بعدی صفر و \n",
    "$1$\n",
    "ذخیره کرد و نمایش داد.\n",
    "به این صورت که اگر کاربر، کتاب $i$-ام \n",
    "را مطالعه کرده باشد خانه‌ی مربوط به آن $1$\n",
    "و در غیر این صورت صفر باشد.\n",
    "می‌توانیم تعاریف مختلفی از شباهت یا فاصله را بر اساس کاربردی مورد نظرمان انتخاب کنیم. مثلا می‌توانیم شباهت دو نفر را تعداد کتاب‌های مشترکی که مطالعه کرده‌اند در نظر بگیریم (ایراد این تعریف در عمل چیست؟).\n",
    "\n",
    "یکی از تعاریفی که در عمل خوب کار می‌کند شاخص Jaccard است که شباهت دو مجموعه‌ی $A$ و $B$ را به صورت زیر تعریف می‌کند:\n",
    "<br>\n",
    "$$\\frac{|A \\cap B|}{|A \\cup B|}$$\n",
    "در این مثال شباهت دو کاربر از دید شاخص Jaccard برابر با تعداد کتاب‌های مشترکی که مطالعه کرده‌اند تقسیم بر تعداد کل کتاب‌هایی که خوانده‌اند است.\n",
    "\n",
    "<br>\n",
    "<i>تمرین: برای \n",
    "دو زیرمجموعه‌ی \n",
    "$m$ \n",
    "عضوی تصادفی از اعداد 1 تا $n$ \n",
    "امید ریاضی شاخص Jaccard را محاسبه کنید.</i>\n",
    "</font></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.25\n",
      "0.4\n"
     ]
    }
   ],
   "source": [
    "n = 4   # number of users\n",
    "m = 13  # number of books\n",
    "\n",
    "data = [[1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0],\n",
    "        [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0],\n",
    "        [1, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0],\n",
    "        [0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1],\n",
    "       ]\n",
    "\n",
    "def jaccard(A, B):\n",
    "    cap = 0.0\n",
    "    cup = 0.0\n",
    "    for i in range(0, len(A)):\n",
    "        cap = cap + (A[i] and B[i])\n",
    "        cup = cup + (A[i] or B[i])\n",
    "    return cap / cup\n",
    "\n",
    "print jaccard(data[0], data[2])\n",
    "print jaccard(data[0], data[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"direction:rtl;line-height:300%;\"><font face=\"XB Zar\" size=5>\n",
    "\n",
    "<h2><font color=#FF7500 size=5> چالش‌ها </font></h2>\n",
    "ذخیره کردن اطلاعات کاربران در داده‌ساختار‌های ساده مثل آرايه‌ی صفر و $1$\n",
    "که در بخش قبل به آن اشاره کردیم در عمل ممکن است بسیار پر هزینه باشد.\n",
    "برای مثال اگر ۱ میلیون کاربر و ۱۰ هزار کتاب در سیستم داشته باشیم، حجم اطلاعات نمایش جدولی حدود \n",
    "40 ترابایت می‌شود که بارگزاری آن به صورت یکجا در حافظه‌ی اصلی کامپیوتر‌های معمولی (یا حتی کامپیوتر‌های بسیار قدرتمند)\n",
    "ممکن نیست.\n",
    "<br>\n",
    "جدای از مشکل حافظه، محاسبه‌ی شباهت \n",
    "Jaccard\n",
    "دو کاربر از مرتبه‌ی \n",
    "$O(m)$\n",
    "زمان لازم دارد و به همین ترتیب\n",
    "پیدا کردن پرشباهت‌ترین کاربر برای هر کاربر مشخص شده کار بسیار زمان‌بری است و از مرتبه‌ی \n",
    "$O(nm)$\n",
    "زمان می‌برد.\n",
    "<br>\n",
    "با توجه به این چالش‌ها باید یک داده‌ساختار مناسب برای پیدا کردن پرشباهت‌ترین کاربر به ازای هر کاربر داده شده طراحی کنیم، که هم فضای کمتری برای ذخیره‌ی اطلاعات و هم زمان کمتری برای پاسخ دادن به درخواست‌ها نیاز داشته باشد.\n",
    "\n",
    "<h1><font color=#FF7500 size=5>\n",
    "جواب تقریبی\n",
    "</font></h1>\n",
    "پیدا کردن جواب دقیق در زمان و فضای مناسب برای مسئله‌ی شبیه‌ترین فرد یا نزدیک‌ترین نقطه (در ابعداد بالا)، بسیار سخت است و مدت زیادی بدون جواب باقی‌مانده.\n",
    "<br>\n",
    "اما در اکثر کاربردها جواب‌های تقریبی هم کافی هستند. مثلا اگر به جای معرفی کردن شبیه‌ترین کاربر یکی از کاربرهایی که شباهت زیادی دارد را معرفی کنیم احتمالا کاربرها ناراضی نمی‌شوند.\n",
    "<br>\n",
    "به نظر شما صورت تقریبی مسئله را چگونه طرح کنیم؟\n",
    "</font></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"direction:rtl;line-height:300%;\"><font face=\"XB Zar\" size=5>\n",
    "<h1><font color=#FF7500 id=\"section3\" size=6>\n",
    "درهمسازی میانی\n",
    "</font></h1>\n",
    "ایده‌ی اصلی درهمسازی میانی استفاده از تعدادی تابع مستقل درهمساز مثل $h_i(x)$\n",
    "است که به هر مجموعه یک عدد صحیح نسبت می‌دهد، به طوری که به ازای هر \n",
    "$A \\neq B$\n",
    "احتمال تساوی \n",
    "$h_i(A) = h_i(B)$\n",
    "برابر با شباهت \n",
    "$A$\n",
    "و \n",
    "$B$\n",
    "در شاخص \n",
    "Jaccard\n",
    "باشد.\n",
    "اگر تعداد کافی از این تابع‌های درهمساز داشته باشیم می‌توانیم به جای هر $A$\n",
    "، \n",
    "مقدار $h_i(A)$\n",
    "‌ها\n",
    "را نگهداری کنیم. با توجه به قانون اعداد بزرگ، با افزایش تعداد \n",
    "$h_i(A)$\n",
    "ها \n",
    "برای هر دو مجموعه‌ی مختلف نسبت تعداد hash های برابر به کل تعداد hash ها بسیار نزدیک به شباهت \n",
    "Jaccard\n",
    "آن‌ها خواهد بود.\n",
    "\n",
    "<h1><font color=#FF7500 size=5>\n",
    "درهمسازی میانی در مثال شبکه اجتماعی کتاب‌خوان‌ها \n",
    "</font></h1>\n",
    "فرض کنید کتاب‌ها را با شماره‌های 1 تا $m$\n",
    "شماره‌گذاری کرده‌ایم.\n",
    "مجموعه‌ی کتاب‌هایی که یک کاربر مطالعه کرده‌است را $A$ در نظر بگیرید،\n",
    "یک تابع مناسب برای درهمسازی میانی تابع زیر است:\n",
    "<br>\n",
    "$$\n",
    "h(A) = min_{x \\in A} x \n",
    "$$\n",
    "\n",
    "یعنی کمترین شماره بین شماره‌ی کتاب‌هایی که این کاربر مطالعه کرده.\n",
    "<br>\n",
    "<i>تمرین: دو مجموعه‌ی مختلف $A$ و $B$ را در نظر بگیرید و فرض کنید کتاب‌ها به صورت تصادفی شماره‌گذاری شده‌اند (یعنی جایگشت کتاب‌ها با احتمال برابر از بین همه‌ی جایگشت‌های ممکن انتخاب شده است). ثابت کنید احتمال\n",
    "$h(A) = h(B)$\n",
    "برابر است با $\\frac{|A \\cap B|}{|A \\cup B|}$. </i>\n",
    "</font></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "def min_hash(A):\n",
    "    for i in range(0, len(A)):\n",
    "        if A[i] == 1:\n",
    "            return i\n",
    "    return -1\n",
    "\n",
    "print min_hash(data[0])\n",
    "print min_hash(data[1])\n",
    "print min_hash(data[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"direction:rtl;line-height:300%;\"><font face=\"XB Zar\" size=5>\n",
    "اگر کتاب‌ها را با یک جایگشت تصادفی جدید شماره‌گذاری کنیم همان تابع $h(A)$ تبدیل به یک تابع مستقل جدید می‌شود که شرایط درهمسازی میانی را دارد. \n",
    "<br>\n",
    "پس برای محسابه‌ی hash اطلاعات کاربران، می‌توانیم در ابتدا تعدادی جایگشت تصادفی انتخاب کنیم و نسبت به هر کدام تابع $h(A)$\n",
    "را محاسبه کنیم.\n",
    "</font></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0, 1, 0, 1, 0], [1, 3, 3, 3, 0], [0, 1, 0, 1, 1], [3, 0, 1, 0, 3]]\n",
      "(0, 0, 0.0)\n",
      "(0, 1, 0.2)\n",
      "(0, 2, 0.55)\n",
      "(0, 3, 0.1111111111111111)\n",
      "(1, 0, 0.2)\n",
      "(1, 1, 0.0)\n",
      "(1, 2, 0.0)\n",
      "(1, 3, 0.0)\n",
      "(2, 0, 0.55)\n",
      "(2, 1, 0.0)\n",
      "(2, 2, 0.0)\n",
      "(2, 3, 0.0)\n",
      "(3, 0, 0.1111111111111111)\n",
      "(3, 1, 0.0)\n",
      "(3, 2, 0.0)\n",
      "(3, 3, 0.0)\n",
      "average error = 0.11\n"
     ]
    }
   ],
   "source": [
    "import numpy\n",
    "\n",
    "def min_hash(A, p):\n",
    "    for i in range(0, len(A)):\n",
    "        if A[p[i]] == 1:\n",
    "            return i\n",
    "    return -1\n",
    "\n",
    "def approximated_jaccard(A, B):\n",
    "    both = 0\n",
    "    for i in range(0, len(A)):\n",
    "        both = both + (A[i] == B[i])\n",
    "    return 1.0 * both / len(A)\n",
    "    \n",
    "P = [numpy.random.permutation(n), \n",
    "     numpy.random.permutation(n), \n",
    "     numpy.random.permutation(n), \n",
    "     numpy.random.permutation(n),     \n",
    "     numpy.random.permutation(n)] # random permutations\n",
    "\n",
    "hashed_data = []\n",
    "\n",
    "for i in range(0, n):\n",
    "    res = []\n",
    "    for j in range(0, len(P)):\n",
    "        res.append(min_hash(data[i], P[j]))\n",
    "    hashed_data.append(res)\n",
    "\n",
    "print hashed_data\n",
    "\n",
    "sum_error = 0\n",
    "for i in range(0, n):\n",
    "    for j in range(0, n):\n",
    "        print(i, j, abs(jaccard(data[i], data[j]) - approximated_jaccard(hashed_data[i], hashed_data[j])))\n",
    "        sum_error += abs(jaccard(data[i], data[j]) - approximated_jaccard(hashed_data[i], hashed_data[j])) \n",
    "print('average error = %.2f' % (sum_error / n / n))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"direction:rtl;line-height:300%;\"><font face=\"XB Zar\" size=5>\n",
    "روشن است که هرچه تعداد جایگشت‌های تصادفی بیشتری انتخاب کنیم دقت تقریب بیشتر می‌شود. یکی از سوالات مهم این است که برای رسیدن به یک دقت معین، چه تعداد جایگشت تصادفی کافی است؟ فرض کنید ۵۰۰ کاربر و ۱۰۰۰ کتاب در سیستم داریم، سعی کنید با تولید داده‌های تصادفی (مثلا می‌توانید فرض کنید هر کاربر هر کتاب را به احتمال 0.005 مطالعه کرده‌است) تعداد جایگشت‌های تصادفی ایی را پیدا کنید که میانگین خطا با در نظر گرفتن داده‌های hash شده به جای داده‌های اصلی حداکثر 0.05 شود.\n",
    "</font></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "n = 500\n",
    "m = 1000\n",
    "\n",
    "random_data = []\n",
    "for user in range(0, n):\n",
    "    d = []\n",
    "    for book in range(0, m):\n",
    "        r = random.uniform(0, 1)\n",
    "        if r <= 0.005:\n",
    "            d.append(1)\n",
    "        else:\n",
    "            d.append(0)\n",
    "    random_data.append(d)\n",
    "\n",
    "\n",
    "# complete this code and find appropriate number of random permutations!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"direction:rtl;line-height:300%;\"><font face=\"XB Zar\" size=5>\n",
    "<h1><font color=#FF7500 id=\"section5\" size=6>\n",
    "درهمسازی حساس به شباهت</font></h1>\n",
    "درهمسازی میانی یک نمونه از درهمسازی حساس به شباهت است. به طور کلی یک درهمسازی حساس به شباهت مجموعه‌ای از توابع مستقل از هم است که با چهار پارامتر \n",
    "$d_1 < d_2$ و  $p_1 > p_2$\n",
    "تعریف می‌شود و هر کدام از توابع باید خواص زیر را برای هر دو نقطه‌ی $x$ و $y$ داشته باشد:\n",
    "<br>\n",
    "۱. اگر فاصله‌ی $x$ و $y$ کمتر از $d_1$ است احتمال یکی شدن hash این دو نقطه باید دست کم $p_1$ باشد.\n",
    "<br>\n",
    "۲. اگر فاصله‌ی $x$ و $y$ بیشتر از $d_2$ است احتمال یکی شدن hash این دو نقطه باید دست بالا $p_2$ باشد.\n",
    "\n",
    "<img src='src/images/Capture.PNG'>\n",
    "<br> \n",
    "همانطور که در مثال درهمسازی میانی دیدیم، با توجه به استقلال این توابع می‌توان با ترکیب آن‌ها به دقت مطلوب رسید.\n",
    "می‌توانید این چهار پارامتر را برای روش درهم‌سازی میانی تعیین کنید ؟\n",
    "</font></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"direction:rtl;line-height:300%;\"><font face=\"XB Zar\" size=5>\n",
    "<h1><font color=#FF7500 id=\"section4\" size=6>\n",
    "شبیه‌ترین کاربر (نزدیک‌ترین همسایه)\n",
    "</font></h1>\n",
    "با اینکه توانستیم با استفاده از روش درهمسازی میانی فضای مورد نیاز برای ذخیره‌سازی داده‌ها و همچنین زمان مقایسه‌ی دو کاربر را کاهش دهیم ولی هنوز پیدا کردن نزدیک‌ترین کاربر به یک کاربر دلخواه دست کم از مرتبه‌ی $O(n)$ است و هنوز زمانبر است.\n",
    "<br>\n",
    "یک ایده چند بار استفاده از روش درهمسازی میانی است! با این کار به احتمال بالا، بعد از چند مرحله کاربر‌هایی که به هم شبیه هستند در یک دسته قرار می‌گیرند.\n",
    "</font></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# TODO:\n",
    "# Example needed here. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"direction:rtl;line-height:300%;\"><font face=\"XB Zar\" size=5>\n",
    "<h1><font color=#FF7500 id=\"section6\" size=6>\n",
    "شبیه‌ترین کتاب!\n",
    "</font></h1>\n",
    "در بخش‌های قبل این درسنامه سعی کردیم نزدیک‌ترین کاربر به هر کاربر را به صورت تقریبی و با هزینه‌ی مناسب پیدا کنیم. فرض کنید متن کتاب‌ها را داریم و اینبار می‌خواهیم به ازای هر کتاب داده شده نزدیک‌ترین کتاب را پیدا کنیم.\n",
    "<br>\n",
    "مهمترین سوالی که باید به آن پاسخ بدهیم این است که معیار شباهت دو کتاب یا دو رشته‌ی متنی چیست؟\n",
    "تا این‌جا فقط با معیار شباهت\n",
    "Jaccard\n",
    "آشنا شدیم. آیا می‌توانیم برای تعیین شباهت دو کتاب یا دو رشته از معیار \n",
    "Jaccard\n",
    "استفاده کنیم؟\n",
    "\n",
    "<h1><font color=#FF7500 size=5>\n",
    "کیسه‌ی کلمات!\n",
    "</font></h1>\n",
    "می‌توانیم از روی هر متن یک مجموعه‌ی نظیر شامل کلمات آن متن بسازیم. با توجه به این که مجموعه‌ی کلماتی که در دو متن متفاوت با محتوای شبیه به هم استفاده می‌شوند اشتراکات بیشتری از مجموعه کلمات دو متن با موضوعات متفاوت دارند، شاخص Jaccard مجموعه‌های نظیر دو متن معیار قابل قبولی از شابهت متن‌ها به هم ارائه می‌کند.\n",
    "<br>\n",
    "به عنوان مثال احتمال تکرار کلمات \"الگوریتم\" یا \"گراف\" در یک متن با موضوع علوم کامپیوتر بسیار بیشتر از احتمال تکرار این کلمات در متنی با موضوع فیلم‌سازی است.\n",
    "<br>\n",
    "برای مثال چهار متن از ابتدای چهار مقاله‌ی مختلف، دو تا با موضوع درهمسازی حساس به شباهت و دو تا با موضوع فیلم‌سازی را مقایسه می‌کنیم.\n",
    "</font></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.00 0.10 0.08 0.09 \n",
      "0.10 1.00 0.06 0.05 \n",
      "0.08 0.06 1.00 0.10 \n",
      "0.09 0.05 0.10 1.00 \n"
     ]
    }
   ],
   "source": [
    "# 0.txt, 1.txt about LSH\n",
    "# 2.txt, 3.txt about Filmmaking\n",
    "\n",
    "all_words = set()\n",
    "book_words = []\n",
    "data = []\n",
    "\n",
    "for i in range(0, 4):\n",
    "    with open('./src/%d.txt' % i) as f:\n",
    "        set_of_words = set([word for line in f for word in line.replace('.', ' ').split()])\n",
    "        book_words.append(set_of_words)\n",
    "        all_words = all_words.union(set_of_words)\n",
    "\n",
    "for i in range(0, 4):\n",
    "    d = []\n",
    "    for w in all_words:\n",
    "        if w in book_words[i]:\n",
    "            d.append(1)\n",
    "        else:\n",
    "            d.append(0)\n",
    "    data.append(d)\n",
    "\n",
    "for i in range(0, 4):\n",
    "    sim = []\n",
    "    for j in range(0, 4):\n",
    "        sim.append(jaccard(data[i], data[j]))\n",
    "    print(\"%.2f \"*len(sim) % tuple(sim))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"direction:rtl;line-height:300%;\"><font face=\"XB Zar\" size=5>\n",
    "نتایج خیلی خوب نیست! اگر کلمات پر تکرار و کلمات کم تکرار وزن متفاوتی داشته باشند نتایج به مراتب بهتر می‌شود.\n",
    "کد قسمت قبل را جوری تغییر دهید که نسبت به تکرار کلمات حساس باشد.\n",
    "<br>\n",
    "همچنین می‌توانیم با حذف کلمات و علائم تکراری و بدون ارزش معنایی مثل حروف ربط یا نقطه به نتیجه‌ی بهتری برسیم.\n",
    "\n",
    "</font></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"direction:rtl;line-height:300%;\"><font face=\"XB Zar\" size=5>\n",
    "<h1><font color=#FF7500 size=5>\n",
    "گروه کلمات به جای تک کلمه\n",
    "</font></h1>\n",
    "یک ایده برای افزایش دقت شاخص Jaccard \n",
    "اضافه کردن همه‌ی ترکیب‌های حاصل از دو یا چند کلمه‌ی مجاور به جای کلمات تکی است.\n",
    "می‌توانید این بهبود عملکرد را توجیه کنید؟\n",
    "</font></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"direction:rtl;line-height:300%;\"><font face=\"XB Zar\" size=5>\n",
    "<h1><font color=#FF7500 size=6>\n",
    "منابع\n",
    "</font></h1>\n",
    "<p style=\"direction:ltr;\">\n",
    "1. <a href='http://www.mmds.org/'>\n",
    "Mining of Massive Dataasets <i> <font face=\"XB Zar\" size=4> by Anand Rajaraman and Jeffrey D. Ullman </font> </i> </a>\n",
    "<br>\n",
    "2. <a href='https://people.csail.mit.edu/indyk/39.ps'>\n",
    "Nearest Neighbors in High-dimensional Spaces <i> <font face=\"XB Zar\" size=4> by Piotr Indyk </font> </i> </a> \n",
    "\n",
    "</p>\n",
    "</font></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
